# RÃ©sultats d'Optimisation - Orderbook Vec vs HashMap

Date : 2025-10-23

## Vue d'ensemble

Ce document compare les performances de deux implÃ©mentations du carnet d'ordres L2 :
- **HashMap (Suboptimal)** : Stockage des niveaux de prix dans un HashMap<Price, Qty>
- **Vec (Optimized)** : Stockage des niveaux de prix dans un Vec<Qty> avec indexation directe

## RÃ©sultats principaux

### 1. Performance des mises Ã  jour (update)

| OpÃ©ration | HashMap | Vec | AmÃ©lioration |
|-----------|---------|-----|--------------|
| **Single update** | 1.56 Âµs | **0.97 Âµs** | **1.6x plus rapide** |
| **Batch 100 updates** | 167.55 Âµs | **89.70 Âµs** | **1.87x plus rapide** |

**Analyse** : L'implÃ©mentation Vec est **60-87% plus rapide** pour les opÃ©rations de mise Ã  jour. Cela s'explique par :
- AccÃ¨s O(1) au lieu de O(log n) ou hash lookup
- Pas de calcul de hash
- Meilleure localitÃ© du cache (accÃ¨s sÃ©quentiel)

### 2. Performance des opÃ©rations de lecture

| OpÃ©ration | HashMap | Vec | AmÃ©lioration |
|-----------|---------|-----|--------------|
| **best_bid()** | 160.42 ns | **1.19 ns** | **134x plus rapide** ğŸš€ |
| **best_ask()** | 164.98 ns | **1.17 ns** | **141x plus rapide** ğŸš€ |
| **mid_price()** | 332.24 ns | **0.65 ns** | **511x plus rapide** ğŸš€ğŸš€ğŸš€ |
| **orderbook_imbalance()** | 365.50 ns | **0.67 ns** | **545x plus rapide** ğŸš€ğŸš€ğŸš€ |
| **top_bids(10)** | 209.18 ns | 402.05 ns | 1.9x plus lent âš ï¸ |

**Analyse** :
- âœ… **Lecture des meilleurs prix** : AmÃ©lioration **extrÃªme** (100-500x) grÃ¢ce au cache
- âœ… **Calculs dÃ©rivÃ©s** (mid_price, imbalance) : Sub-nanoseconde grÃ¢ce au cache
- âš ï¸ **Top N levels** : LÃ©gÃ¨rement plus lent car nÃ©cessite un scan du Vec (mais reste < 500 ns)

### 3. Performance selon la profondeur du carnet

#### Profondeur = 5 niveaux

| ImplÃ©mentation | Temps |
|----------------|-------|
| HashMap | 954.83 ns |
| Vec | **703.41 ns** |
| **AmÃ©lioration** | **1.36x** |

#### Profondeur = 10 niveaux

| ImplÃ©mentation | Temps |
|----------------|-------|
| HashMap | 1.047 Âµs |
| Vec | **0.751 Âµs** |
| **AmÃ©lioration** | **1.39x** |

#### Profondeur = 20 niveaux

| ImplÃ©mentation | Temps |
|----------------|-------|
| HashMap | 1.476 Âµs |
| Vec | **0.788 Âµs** |
| **AmÃ©lioration** | **1.87x** |

#### Profondeur = 50 niveaux

| ImplÃ©mentation | Temps |
|----------------|-------|
| HashMap | 3.434 Âµs |
| Vec | **1.055 Âµs** |
| **AmÃ©lioration** | **3.25x** ğŸš€ |

**Analyse** : L'avantage de Vec **augmente avec la profondeur** du carnet. Ã€ 50 niveaux, Vec est **3.25x plus rapide**.

## Graphique de comparaison

```
Performance Comparison (lower is better)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Update Operations:
Single update       HashMap: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.56 Âµs
                    Vec:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.97 Âµs  (1.6x faster)

Batch 100 updates   HashMap: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 167.55 Âµs
                    Vec:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 89.70 Âµs  (1.87x faster)

Read Operations:
best_bid()          HashMap: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 160.42 ns
                    Vec:     â–1.19 ns  (134x faster)

mid_price()         HashMap: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 332.24 ns
                    Vec:     â–0.65 ns  (511x faster)

Depth Scaling:
depth=50            HashMap: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 3.43 Âµs
                    Vec:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1.06 Âµs  (3.25x faster)
```

## Architecture de l'implÃ©mentation optimisÃ©e

### StratÃ©gie de stockage

```rust
pub struct L2Book {
    bid_anchor: Price,    // Prix de rÃ©fÃ©rence pour les bids
    ask_anchor: Price,    // Prix de rÃ©fÃ©rence pour les asks

    bids: Vec<Qty>,       // Index = (bid_anchor - price_tick)
    asks: Vec<Qty>,       // Index = (price_tick - ask_anchor)

    // Cache pour O(1) read operations
    cached_best_bid: Option<(Price, Qty)>,
    cached_best_ask: Option<(Price, Qty)>,
}
```

### Avantages de cette approche

1. **AccÃ¨s O(1)** : Conversion directe prix â†’ index
2. **Cache CPU-friendly** : Les prix proches sont contigus en mÃ©moire
3. **Cache des best prices** : Lecture en temps constant
4. **Pas d'allocation** : RÃ©utilisation du Vec prÃ©-allouÃ©
5. **ScalabilitÃ©** : Performance proportionnellement meilleure avec plus de niveaux

### Trade-offs

| Aspect | HashMap | Vec |
|--------|---------|-----|
| Insertion/Update | O(1) avg, O(n) worst | O(1) constant |
| Lecture best price | O(n) | **O(1)** âœ… |
| MÃ©moire | Dynamique (sparse) | Statique (dense) |
| LocalitÃ© cache | Mauvaise | **Excellente** âœ… |
| Expansion dynamique | Facile | NÃ©cessite resize |

## Throughput calculÃ©

### Mises Ã  jour par seconde

| ImplÃ©mentation | Single update | Batch |
|----------------|---------------|-------|
| HashMap | ~640,000 updates/s | ~596,000 updates/s |
| **Vec** | **~1,030,000 updates/s** | **~1,115,000 updates/s** |

### Lectures par seconde

| OpÃ©ration | HashMap | Vec |
|-----------|---------|-----|
| best_bid() | ~6.2M reads/s | **~840M reads/s** |
| mid_price() | ~3.0M reads/s | **~1.5B reads/s** |

## Recommandations

### âœ… Utiliser Vec (Optimized) quand :

1. **Latence critique** : Besoin de < 1 Âµs par update
2. **Lecture intensive** : Beaucoup d'accÃ¨s aux best prices
3. **Carnet profond** : Plus de 20 niveaux de profondeur
4. **Trading haute frÃ©quence** : Chaque nanoseconde compte

### âš ï¸ Utiliser HashMap (Suboptimal) quand :

1. **Prix trÃ¨s dispersÃ©s** : Range de prix > 10,000 ticks
2. **Carnet sparse** : Peu de niveaux actifs
3. **SimplicitÃ©** : Pas besoin d'optimisation extrÃªme
4. **Prototypage rapide**

## Cas d'usage rÃ©el : Market Making HFT

### ScÃ©nario typique
- Mise Ã  jour du carnet : 10,000 fois/seconde
- Lecture du mid-price : 100,000 fois/seconde
- Profondeur utilisÃ©e : 20 niveaux

### Performance HashMap
```
Updates:  10,000 Ã— 1.56 Âµs = 15.6 ms/s = 1.56% CPU
Reads:    100,000 Ã— 332 ns = 33.2 ms/s = 3.32% CPU
Total:    4.88% CPU
```

### Performance Vec (Optimized)
```
Updates:  10,000 Ã— 0.97 Âµs = 9.7 ms/s = 0.97% CPU
Reads:    100,000 Ã— 0.65 ns = 0.065 ms/s = 0.0065% CPU
Total:    0.98% CPU
```

**Ã‰conomie** : **4.98x moins de CPU** utilisÃ© !

## Tests de validation

Tous les tests unitaires passent pour les deux implÃ©mentations :

```bash
cargo test
```

### Tests d'Ã©quivalence

âœ… Bootstrap update identique
âœ… Sequential updates identiques
âœ… Best bid/ask identiques
âœ… Mid-price identiques
âœ… Orderbook imbalance identiques
âœ… Checksum validation identique

## Conclusion

L'implÃ©mentation optimisÃ©e avec Vec offre des **gains de performance spectaculaires** :

- **1.6-1.9x plus rapide** pour les updates
- **100-500x plus rapide** pour les lectures
- **ScalabilitÃ© excellente** avec la profondeur
- **Consommation CPU rÃ©duite de 5x**

Cette implÃ©mentation est **production-ready** pour des systÃ¨mes HFT Ã  faible latence et convient parfaitement aux stratÃ©gies de market making nÃ©cessitant des accÃ¨s ultra-rapides au carnet d'ordres.

## Prochaines Ã©tapes d'optimisation

1. **SIMD** : Utiliser des instructions vectorielles pour les calculs d'imbalance sur plusieurs niveaux
2. **Zero-copy** : Ã‰viter les allocations dans top_bids()/top_asks()
3. **Atomic operations** : Support multi-thread lock-free
4. **Memory pool** : PrÃ©-alloquer les messages pour Ã©viter les allocations
5. **Branch prediction hints** : Optimiser les chemins chauds avec likely/unlikely

## RÃ©fÃ©rences

- Code source : `src/optimized/book.rs`
- Benchmarks : `benches/optimized_vs_suboptimal.rs`
- Documentation : `benches/README.md`
