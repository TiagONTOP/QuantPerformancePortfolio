# 04_gpu_monte_carlo â€” Monte Carlo Pricing Optimization with CuPy

This project is a quantitative-finance case study on performance optimization, demonstrating the **massive acceleration** achieved by porting a Monte Carlo (MC) pricing simulation from **CPU (NumPy)** to **GPU (CuPy)**.

The example focuses on pricing an **Asian option**, whose value depends on the simulated average of a **Geometric Brownian Motion (GBM)** process.

-----

## ðŸŽ¯ Project Objective

The goal is to quantitatively compare two implementations of GBM path generation:

1.  **Baseline (`suboptimal/pricing.py`)** â€” a standard vectorized implementation using **NumPy**.
    Efficient on CPU, but limited by the inherently sequential (or lightly parallel) nature of CPU execution.

2.  **Optimized (`optimized/pricing.py`)** â€” a GPU-based implementation using **CuPy**, a drop-in replacement for NumPy that runs computations on NVIDIA GPUs.
    The two codes are almost identical semantically, illustrating a *drop-in optimization* approach that exploits massive GPU parallelism without rewriting core logic.

-----

## ðŸš€ Key Results â€” The â€œSpeedupâ€

The acceleration from NumPy â†’ CuPy is significant, especially for large simulation sizes and single-precision arithmetic.

For the â€œLargeâ€ problem (100,000 paths Ã— 252 timesteps), based on the methodologically-sound benchmark results:

| Backend | Precision | Execution Time | **Speedup (vs CPU float32)** |
| :--- | :--- | :--- | :--- |
| **CPU (NumPy)** | `float32` | **0.482 s** | 1.0Ã— |
| **GPU (CuPy)** | `float32` | **0.078 s** | **6.20Ã—** |

### Precision Trade-Off â€” FP32 vs FP64

A crucial finding is the impact of numerical precision (`dtype`) on performance:

  - **Single precision (`float32`)** â€” delivers the **maximum speedup (6.20Ã—)**.
    Ideal for most consumer GPUs where FP32 units dominate.

  - **Double precision (`float64`)** â€” provides smaller gains.
    On the test GPU (NVIDIA GTX 980 Ti, Maxwell), the speedup for the same "Large" problem was only **3.30x**, and for the "Very Large" problem, the GPU was **0.83x** (slower than the CPU). This confirms that FP64 throughput is a significant bottleneck on this hardware.

For Monte Carlo pricing, where statistical noise usually outweighs machine precision, **`float32` is almost always optimal**.

Full benchmark data are available in [`docs/BENCHMARKS.md`](https://www.google.com/search?q=./docs/BENCHMARKS.md) and `tests/performance_report.txt`.

### âœ¨ Zero-Copy GPU Pipeline

**New capability**: The project now supports a **zero-copy GPU pipeline** where both simulation and pricing run entirely on GPU, eliminating CPU-GPU memory transfers.

Using `device_output=True` with the backend-agnostic `price_asian_option()` function enables an additional **1.2-2.0Ã— speedup** over the standard pipeline, bringing total acceleration to **~7.5-12.5Ã— vs CPU**.

See [`docs/CORRECTIONS_APPLIED.md`](https://www.google.com/search?q=./docs/CORRECTIONS_APPLIED.md) for technical details.

-----

## ðŸ“‚ Project Structure

```

04_gpu_monte_carlo/                   
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ BENCHMARKS.md                  # Detailed performance analysis
â”‚   â”œâ”€â”€ README.md                      # Documentation landing page
â”‚   â”œâ”€â”€ STRUCTURE.md                   # Technical implementation details
â”‚   â””â”€â”€ TESTS.md                       # Test documentation
â”œâ”€â”€ optimized/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ pricing.py                     # Optimized GPU implementation (CuPy)
â”œâ”€â”€ suboptimal/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ pricing.py                     # Baseline CPU implementation (NumPy)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ benchmark_results.txt          # Aggregated benchmark results
â”‚   â”œâ”€â”€ generate_performance_report.py # Generates detailed performance report
â”‚   â”œâ”€â”€ performance_report.txt         # Exported performance summary
â”‚   â”œâ”€â”€ run_all_tests_and_benchmarks.py# Runs all tests and benchmarks
â”‚   â”œâ”€â”€ test_asian_option_benchmark_zero_copy.py # Zero-copy pipeline benchmark
â”‚   â”œâ”€â”€ test_asian_option_benchmark.py # Asian option pricing benchmarks
â”‚   â”œâ”€â”€ test_asian_option_correctness.py # Asian option pricing correctness
â”‚   â”œâ”€â”€ test_benchmark_gpu.py          # GPU benchmark suite
â”‚   â”œâ”€â”€ test_correctness_gpu.py        # GPU vs CPU numerical parity tests
â”‚   â”œâ”€â”€ test_correctness.py            # Generic correctness tests
â”‚   â””â”€â”€ test_results.txt               # Consolidated test output logs
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml                     # Poetry configuration and dependencies
â””â”€â”€ utils.py                           # Shared utility functions
````

-----

## ðŸ› ï¸ Installation & Usage

This project uses [**Poetry**](https://python-poetry.org/) for dependency and environment management.

```bash
# 1. Navigate to the project directory
cd case_studies/04_gpu_monte_carlo

# 2. Install Poetry (if not already installed)
pip install poetry

# 3. Configure Poetry to create a local .venv
poetry config virtualenvs.in-project true

# 4. Install dependencies
poetry install --no-root

# 5. Activate the virtual environment
.venv\Scripts\activate
````

### Installing CuPy (for CUDA 11/12)

Choose the build matching your CUDA Toolkit:

```bash
# For CUDA 12.x
pip install cupy-cuda12x

# For CUDA 11.x (or if CUDA 12 fails)
pip install cupy-cuda11x
```

-----

## â–¶ï¸ Running Tests and Benchmarks

### Quick Validation

Validate that all corrections are working correctly:

```bash
# Validate backend-agnostic pricing and zero-copy pipeline
python scripts/validate_fixes.py
```

This script tests:

  - Backend detection (NumPy/CuPy)
  - CPU pricer with NumPy arrays
  - GPU pricer with CuPy arrays (zero-copy)
  - Pipeline consistency
  - Call/Put option types

### Comprehensive Testing

Two main scripts are provided in the `tests/` directory:

```bash
# 1. Generate a detailed performance report with CPU/GPU comparisons
#    Output: tests/performance_report.txt
python tests/generate_performance_report.py

# 2. Run ALL unit tests and benchmarks via pytest
#    Output: tests/test_results.txt (correctness tests)
#            tests/benchmark_results.txt (performance benchmarks)
python tests/run_all_tests_and_benchmarks.py
```

**Note:** These scripts now generate **separate reports**:

  - `performance_report.txt` â€” Detailed performance metrics with CPU/GPU comparisons using identical random seeds
  - `test_results.txt` â€” Correctness test results (GPU correctness, general correctness, Asian option correctness)
  - `benchmark_results.txt` â€” Benchmark test results (GPU benchmarks, Asian benchmarks, zero-copy benchmarks)

### Zero-Copy Pipeline Benchmark

To measure the performance gain of the zero-copy GPU pipeline:

```bash
# Run comprehensive zero-copy benchmark suite
python tests/test_asian_option_benchmark_zero_copy.py
```

This demonstrates the additional speedup achieved by keeping all data on GPU.

-----

## ðŸ–¥ï¸ Benchmark Environment

All benchmarks were run on the following hardware:

| Component | Specification |
| :--- | :--- |
| **CPU** | Intel Core i7-4770 (Haswell) OC @ 4.1 GHz |
| **Motherboard** | ASUS Z87 |
| **RAM** | 16 GB DDR3 @ 2400 MHz |
| **GPU** | NVIDIA GeForce GTX 980 Ti (OC) |
| | *Architecture:* Maxwell (2nd Gen) |
| | *Compute Capability:* 5.2 |

-----

> âš¡ **Summary:** By swapping NumPy for CuPy with almost no code changes, Monte Carlo pricing achieves a **6.2Ã— GPU acceleration** on mid-range hardware â€” a striking illustration of how quantitative-finance simulations can benefit from GPU parallelism.

```