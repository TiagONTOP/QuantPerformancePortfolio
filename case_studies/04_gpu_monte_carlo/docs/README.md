# 04\_gpu\_monte\_carlo â€” Monte Carlo Pricing Optimization with CuPy

This project is a quantitative-finance case study on performance optimization, demonstrating the **massive acceleration** achieved by porting a Monte Carlo (MC) pricing simulation from **CPU (NumPy)** to **GPU (CuPy)**.

The example focuses on pricing an **Asian option**, whose value depends on the simulated average of a **Geometric Brownian Motion (GBM)** process.

-----

## ðŸŽ¯ Project Objective

The goal is to quantitatively compare two implementations of GBM path generation:

1.  **Baseline (`suboptimal/pricing.py`)** â€” a standard vectorized implementation using **NumPy**.
    Efficient on CPU, but limited by the inherently sequential (or lightly parallel) nature of CPU execution.

2.  **Optimized (`optimized/pricing.py`)** â€” a GPU-based implementation using **CuPy**, a drop-in replacement for NumPy that runs computations on NVIDIA GPUs.
    The two codes are almost identical semantically, illustrating a *drop-in optimization* approach that exploits massive GPU parallelism without rewriting core logic.

-----

## ðŸš€ Key Results â€” The "Speedup"

The acceleration from NumPy â†’ CuPy is **massive**, especially for large simulation sizes and single-precision arithmetic.

For the "Large" problem (500,000 paths Ã— 252 timesteps), based on verified benchmark results:

| Backend | Precision | Execution Time | **Speedup (vs CPU)** |
| :--- | :--- | :--- | :--- |
| **CPU (NumPy)** | `float32` | **4.785 s** | 1.0Ã— (baseline) |
| **GPU (CuPy) â€” Standard** | `float32` | **0.349 s** | **13.7Ã—** |
| **GPU (CuPy) â€” Zero-Copy** | `float32` | **0.114 s** | **42.0Ã—** âš¡ |

### Precision Trade-Off â€” FP32 vs FP64

A crucial finding is the impact of numerical precision (`dtype`) on GPU performance:

  - **Single precision (`float32`)** â€” delivers **maximum performance**.
    On the test GPU, `float32` is **1.81Ã— faster** than `float64` for the same problem.
    Ideal for Monte Carlo simulations where statistical noise dominates machine precision.

  - **Double precision (`float64`)** â€” still provides strong speedup (**7.2Ã— vs CPU**).
    Use when high precision is required for validation or sensitivity analysis.

For Monte Carlo pricing, where statistical noise usually outweighs machine precision, **`float32` is the optimal choice**.

Full benchmark data are available in `tests/benchmark_results.txt`.

### âš¡ Zero-Copy GPU Pipeline â€” The Game Changer

**The killer feature**: Our **zero-copy GPU pipeline** keeps both simulation and pricing entirely on GPU, eliminating CPU-GPU memory transfers.

Using `device_output=True` with the backend-agnostic `price_asian_option()` function provides:

  - **3.06Ã— additional speedup** over standard GPU pipeline (0.349s â†’ 0.114s)
  - **Total speedup of 42.0Ã— vs CPU baseline** (4.785s â†’ 0.114s)
  - **156ms of transfer time completely eliminated**

This is the **true power** of GPU optimization: not just faster compute, but **zero-copy architecture**.

-----

## ðŸ“‚ Project Structure

```
04_gpu_monte_carlo/
â”œâ”€â”€ docs/
â”‚ Â  â”œâ”€â”€ BENCHMARKS.md Â  Â  Â  Â  Â  Â  Â  Â  Â # Detailed performance analysis
â”‚ Â  â”œâ”€â”€ README.md Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Documentation landing page (this file)
â”‚ Â  â”œâ”€â”€ STRUCTURE.md Â  Â  Â  Â  Â  Â  Â  Â  Â  # Technical implementation details
â”‚ Â  â””â”€â”€ TESTS.md Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Test suite documentation
â”œâ”€â”€ optimized/
â”‚ Â  â”œâ”€â”€ __init__.py
â”‚ Â  â””â”€â”€ pricing.py Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Optimized GPU implementation (CuPy)
â”œâ”€â”€ suboptimal/
â”‚ Â  â”œâ”€â”€ __init__.py
â”‚ Â  â””â”€â”€ pricing.py Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Baseline CPU implementation (NumPy)
â”œâ”€â”€ tests/
â”‚ Â  â”œâ”€â”€ test_correctness.py Â  Â  Â  Â  Â  Â # âœ… ALL correctness tests (44 tests)
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - GBM simulation tests (CPU + GPU)
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - Asian option pricing tests
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - Input validation tests
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - Statistical parity tests
â”‚ Â  â”œâ”€â”€ test_benchmark.py Â  Â  Â  Â  Â  Â  Â # âš¡ ALL performance benchmarks (14 benchmarks)
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - Small/Medium/Large problem sizes
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - CPU vs GPU comparisons
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - Zero-copy pipeline benchmarks
â”‚ Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Â  Â - Memory transfer analysis
â”‚ Â  â””â”€â”€ benchmark_results.txt Â  Â  Â  Â  Â # ðŸ“ˆ Generated: performance benchmark results
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Poetry configuration and dependencies
â””â”€â”€ utils.py Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Shared utility functions (Asian option pricer)
```

-----

## ðŸ› ï¸ Installation & Usage

This project uses [**Poetry**](https://python-poetry.org/) for dependency and environment management.

```bash
# 1. Navigate to the project directory
cd case_studies/04_gpu_monte_carlo

# 2. Install Poetry (if not already installed)
pip install poetry

# 3. Configure Poetry to create a local .venv
poetry config virtualenvs.in-project true

# 4. Install dependencies
poetry install --no-root

# 5. Activate the virtual environment
.venv\Scripts\activate
```

### Installing CuPy (for CUDA 11/12)

Choose the build matching your CUDA Toolkit:

```bash
# For CUDA 12.x
pip install cupy-cuda12x

# For CUDA 11.x (or if CUDA 12 fails)
pip install cupy-cuda11x
```

-----

## â–¶ï¸ Running Tests and Benchmarks

```bash
# Run ALL Correctness Tests (44 tests)
python -m pytest tests/test_correctness.py -v

# Run ALL Performance Benchmarks (14 benchmarks)
python -m pytest tests/test_benchmark.py -v -s
```

## ðŸ–¥ï¸ Benchmark Environment

All benchmarks were run on the following hardware:

| Component | Specification |
| :--- | :--- |
| **CPU** | Intel Core i7-4770 (Haswell) OC @ 4.1 GHz |
| **Motherboard** | ASUS Z87 |
| **RAM** | 16 GB DDR3 @ 2400 MHz |
| **GPU** | NVIDIA GeForce GTX 980 Ti (OC) |
| | *Architecture:* Maxwell (2nd Gen) |
| | *Compute Capability:* 5.2 |

-----

> âš¡ **Summary:** By porting the pipeline to CuPy, the standard end-to-end simulation achieves a **13.7Ã— speedup**. By further implementing a **zero-copy architecture** (`device_output=True`), the total acceleration reaches **42.0Ã—** â€” a massive, quantifiable gain from strategic GPU optimization on mid-range hardware.