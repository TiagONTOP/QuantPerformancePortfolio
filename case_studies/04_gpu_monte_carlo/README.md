# 04_gpu_monte_carlo â€” Monte Carlo Pricing Optimization with CuPy

This project is a quantitative-finance case study on performance optimization, demonstrating the **massive acceleration** achieved by porting a Monte Carlo (MC) pricing simulation from **CPU (NumPy)** to **GPU (CuPy)**.

The example focuses on pricing an **Asian option**, whose value depends on the simulated average of a **Geometric Brownian Motion (GBM)** process.

---

## ðŸŽ¯ Project Objective

The goal is to quantitatively compare two implementations of GBM path generation:

1. **Baseline (`suboptimal/pricing.py`)** â€” a standard vectorized implementation using **NumPy**.  
   Efficient on CPU, but limited by the inherently sequential (or lightly parallel) nature of CPU execution.

2. **Optimized (`optimized/pricing.py`)** â€” a GPU-based implementation using **CuPy**, a drop-in replacement for NumPy that runs computations on NVIDIA GPUs.  
   The two codes are almost identical semantically, illustrating a *drop-in optimization* approach that exploits massive GPU parallelism without rewriting core logic.

---

## ðŸš€ Key Results â€” The â€œSpeedupâ€

The acceleration from NumPy â†’ CuPy is dramatic, especially for large simulation sizes and single-precision arithmetic.

For the â€œLargeâ€ problem (100 000 paths Ã— 252 timesteps):

| Backend | Precision | Execution Time | **Speedup (vs CPU float32)** |
| :--- | :--- | :--- | :--- |
| **CPU (NumPy)** | `float32` | â‰ˆ 0.985 s | 1.0Ã— |
| **GPU (CuPy)** | `float32` | **â‰ˆ 0.060 s** | **â‰ˆ 16.4Ã—** |

### Precision Trade-Off â€” FP32 vs FP64

A crucial finding is the impact of numerical precision (`dtype`) on performance:

- **Single precision (`float32`)** â€” delivers the **maximum speedup (~16.4Ã—)**.  
  Ideal for most consumer GPUs where FP32 units dominate.

- **Double precision (`float64`)** â€” provides smaller gains (~1Ã—â€“6Ã—).  
  On the test GPU (NVIDIA GTX 980 Ti, Maxwell), FP64 throughput is only 1â„32 of FP32.

For Monte Carlo pricing, where statistical noise usually outweighs machine precision, **`float32` is almost always optimal**.

Full benchmark data are available in [`BENCHMARKS.md`](./BENCHMARKS.md) and `tests/performance_report.txt`.

---

## ðŸ“‚ Project Structure

```

/
â”œâ”€â”€ optimized/
â”‚   â””â”€â”€ pricing.py          # Optimized GPU implementation (CuPy)
â”œâ”€â”€ suboptimal/
â”‚   â””â”€â”€ pricing.py          # Baseline CPU implementation (NumPy)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_correctness.py          # Numerical-parity unit tests
â”‚   â”œâ”€â”€ test_asian_option_*.py       # Asian-option-specific tests
â”‚   â”œâ”€â”€ test_benchmark_*.py          # Pytest-benchmark scripts
â”‚   â”œâ”€â”€ generate_performance_report.py  # Produces detailed timing report
â”‚   â””â”€â”€ run_all_tests_and_benchmarks.py # Runs all tests + benchmarks
â”œâ”€â”€ pyproject.toml          # Poetry + dependency configuration
â”œâ”€â”€ README.md               # High-level overview (this file)
â”œâ”€â”€ STRUCTURE.md            # Technical implementation details
â”œâ”€â”€ TESTS.md                # Unit-test documentation
â””â”€â”€ BENCHMARKS.md           # Detailed performance analysis

````

---

## ðŸ› ï¸ Installation & Usage

This project uses [**Poetry**](https://python-poetry.org/) for dependency and environment management.

```bash
# 1. Navigate to the project directory
cd case_studies/04_gpu_monte_carlo

# 2. Install Poetry (if not already installed)
pip install poetry

# 3. Configure Poetry to create a local .venv
poetry config virtualenvs.in-project true

# 4. Install dependencies
poetry install --no-root

# 5. Activate the virtual environment
.venv\Scripts\activate
````

### Installing CuPy (for CUDA 11/12)

Choose the build matching your CUDA Toolkit:

```bash
# For CUDA 12.x
pip install cupy-cuda12x

# For CUDA 11.x (or if CUDA 12 fails)
pip install cupy-cuda11x
```

---

## â–¶ï¸ Running Tests and Benchmarks

Two main scripts are provided in the `tests/` directory:

```bash
# 1. Generate a detailed performance report (tests/performance_report.txt)
python tests/generate_performance_report.py

# 2. Run ALL unit tests and benchmarks via pytest
# Results are shown in-console and saved to tests/benchmark_results.txt
python tests/run_all_tests_and_benchmarks.py
```

---

## ðŸ–¥ï¸ Benchmark Environment

All benchmarks were run on the following hardware:

| Component       | Specification                             |
| :-------------- | :---------------------------------------- |
| **CPU**         | Intel Core i7-4770 (Haswell) OC @ 4.1 GHz |
| **Motherboard** | ASUS Z87                                  |
| **RAM**         | 16 GB DDR3 @ 2400 MHz                     |
| **GPU**         | NVIDIA GeForce GTX 980 Ti (OC)            |
|                 | *Architecture:* Maxwell (2nd Gen)         |
|                 | *Compute Capability:* 5.2                 |

---

> âš¡ **Summary:** By swapping NumPy for CuPy with almost no code changes, Monte Carlo pricing achieves a **16Ã— GPU acceleration** on mid-range hardware â€” a striking illustration of how quantitative-finance simulations can benefit from GPU parallelism.